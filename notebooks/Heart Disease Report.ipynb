{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "local-spouse",
   "metadata": {},
   "source": [
    "# Heart Disease Report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tired-security",
   "metadata": {},
   "source": [
    "The dataset used in this report is the Cleveland processed dataset which can be found in the data folder here: https://archive.ics.uci.edu/ml/datasets/Heart+Disease\n",
    "\n",
    "The objective of this study is to apply a classifer to the dataset to predict whether an individual has heart disease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "serial-listening",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from heart_disease import DataLoader, RandomForest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civilian-farming",
   "metadata": {},
   "source": [
    "## Ingest and pre-process the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eligible-record",
   "metadata": {},
   "source": [
    "The data is ingested and pre-processed with the following steps:\n",
    "* Missing data is replaced. There are two missing values in the Thal column which is replaced with the label for normal. There are also 4 missing values in the Number of Major Vessels which are replaced with 0, which is the most common value in the column.\n",
    "* Categorical features are converted into one-hot encoded features.\n",
    "* All values are min-max normalised to be between 0 and 1.\n",
    "\n",
    "Ideas for future improvement:\n",
    "* Further test coverage\n",
    "* Method to version the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "twelve-return",
   "metadata": {},
   "outputs": [],
   "source": [
    "Loader = DataLoader()\n",
    "dataset = Loader.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seven-equation",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "treated-small",
   "metadata": {},
   "source": [
    "## Explore the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mature-sterling",
   "metadata": {},
   "source": [
    "Here a simple pairplot is used to visualise the dataset on a 2D scale. Only a few features are used in the plot below to reduce run time. From the plot we can see that some features such as Number of Major Vessels have noticeable split between heart disease and no heart disease.\n",
    "\n",
    "Ideas for future improvement:\n",
    "* Visualise dataset after applying PCA.\n",
    "* Apply t-SNE to see whether there there is a clear split in a lower-dimensional latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bored-permit",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data=dataset, hue=\"Heart Disease\", vars=[\"Age\", \"Sex\", \"Resting Blood Pressure\", \"Number of Major Vessels\", \"Chest Pain Asymptomatic\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subjective-shopping",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "european-stand",
   "metadata": {},
   "source": [
    "A random forest was chosen to train on this dataset. The reason for this is that a random forest is a good choice for a binary classification problem. Furthermore, the implementation of bagging means that the model is less likely to overfit and the variance of the model is typically lower. Feature importance is also easy to extract by looking at which features decrease the gini impurity the most.\n",
    "\n",
    "In the cells below we train a random forest model on a single train/test split. Afterwards another train/test split is created, from which the train set is used to perform 10-fold cross validation with a parameter grid search. To reduce run time, the number of features searched over and the granularity of the grid search is small. \n",
    "\n",
    "Ideas for future improvements:\n",
    "* Replace k-fold cross validation with leave-one-out. Due to the small nature of the dataset, it would be wise to use LOO to maximise the training set size and ensure a reliable result. A LOO was not implemented here to reduce run time.\n",
    "* Expose more parameters of the random forest model and perform a larger grid search.\n",
    "* Better test coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "experienced-hindu",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, train_labels, test_features, test_labels = Loader.split_dataset(test_size=0.2, balance=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "common-killing",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForest()\n",
    "model, score = rf.train(train_features, train_labels, test_features, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "monetary-active",
   "metadata": {},
   "source": [
    "Perform hyperparameter tuning by utilising K-fold Cross validation. For the sake of reducing the run-time of this notebook, the parameter search here is very minimal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parental-checklist",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = Loader.split_dataset(test_size=0.1, balance=False, split_labels=False)\n",
    "params = {'n_estimators': [100, 250], 'max_depth': [3, None], 'max_features': [7, \"auto\"]}\n",
    "param_scores = rf.perform_k_fold_cv(params, train, folds=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decimal-andrews",
   "metadata": {},
   "source": [
    "# Evaluate Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forty-hungarian",
   "metadata": {},
   "source": [
    "The area under the receiver operating characteristic curve is used to evaluate the model. Further more, F-beta scores are calculated for a range of different values of beta. From the plots it can be seen that the random forest produces a very high AUC score. Furthermore, we can see by altering the threshold we can influence whether the model should prioritise recall or precision.\n",
    "\n",
    "Ideas for future improvement:\n",
    "* Compare the performance to a simple benchmark model (e.g logistic regression)\n",
    "* Add regression tests\n",
    "* Add further directional change tests. (If we perturb the input space we expect the result to increase/decrease. E.g. If we increase the age, we expect the outputted probability to increase). We want coverage across all our features.\n",
    "* Add invariance tests. (A set of pertubations to the input space that we expect won't change the model's output).\n",
    "* Pre-train model tests. (E.g. Model shape aligns with classes, the ranges are within our expectation etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "negative-piece",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels, train_features, feature_list = Loader.features_and_labels_to_numpy(train)\n",
    "test_labels, test_features, _ = Loader.features_and_labels_to_numpy(test)\n",
    "\n",
    "model, score = rf.train(train_features, train_labels, test_features, test_labels, n_estimators=250, max_depth=3, max_features='auto')\n",
    "auc_score = rf.evaluate_model(model, test_features, test_labels, betas=[0.1, 0.5, 1, 2, 5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elegant-bible",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "great-conclusion",
   "metadata": {},
   "source": [
    "Below all the features from the input space are plotted with their respective importance as evaluated from the random forest. It can be seen that the number of major vessels, asymptomatic chest pain and normal thal are the most decisive features to make a prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "devoted-genome",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.plot_feature_importance(model, feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "breathing-harrison",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
